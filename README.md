# üíª Roteiro de Laborat√≥rio 2: Concorr√™ncia e Gargalos em Servidores TCP

**Curso:** Engenharia de Software
**Disciplina:** LABORAT√ìRIO DE DESENVOLVIMENTO DE APLICA√á√ïES M√ìVEIS E DISTRIBU√çDAS
**Professor:** Cristiano de Macedo Neto
**Unidade:** Unidade 0 ‚Äî Nivelamento de conceitos de redes de computadores e Sistemas Operacionais

---

üëã Ol√°, pessoal! Bem-vindos a este laborat√≥rio.

Nesta pr√°tica, vamos consolidar os conceitos de redes de computadores (protocolos TCP/IP, endere√ßamento, backlog de conex√µes) e o ciclo de vida de Threads no Sistema Operacional, observando diretamente as consequ√™ncias de cada decis√£o arquitetural em um servidor de rede.

---

## üéØ Objetivos da Pr√°tica

1. Observar na pr√°tica o funcionamento do protocolo TCP e o comportamento da fila de conex√µes (*backlog*) gerenciada pelo Sistema Operacional.
2. Analisar os gargalos de servidores com I/O bloqueante (*Blocking I/O*).
3. Compreender o custo computacional (*overhead*) e a troca de contexto (*Context Switch*) na concorr√™ncia baseada em Threads.
4. Implementar um servidor ass√≠ncrono (*Event-Driven*) utilizando o modelo de *Event Loop*.

---

## üõ†Ô∏è Prepara√ß√£o do Ambiente

Neste reposit√≥rio voc√™ j√° encontra os seguintes scripts em Python:

- **Simuladores de carga:** `client.py` e `clientenervoso.py`
- **Implementa√ß√µes de servidores:** `serverbloq.py`, `servergargalo.py` e `server.py`

> ‚ö†Ô∏è **Aten√ß√£o:** Todos os testes devem ser executados **exclusivamente em `localhost` (`127.0.0.1`)**, nunca em redes institucionais ou compartilhadas, para evitar impacto em outros usu√°rios e alertas de seguran√ßa da rede.

Clone este reposit√≥rio para sua m√°quina local, abra seu terminal ou IDE de prefer√™ncia e divida a tela para visualizar os logs do cliente e do servidor simultaneamente.

---

## üß™ Etapa 1: O Gargalo Sequencial e o Comportamento da Fila TCP

Nesta etapa observaremos o que acontece quando um servidor bloqueante n√£o consegue atender a demanda e como o Sistema Operacional gerencia a fila de conex√µes pendentes.

### 1.1 Servidor Bloqueante

1. Inicie o `serverbloq.py`.
2. Em outro terminal, execute o `client.py` (3 clientes simult√¢neos).
3. Observe o atendimento **estritamente sequencial**: o servidor s√≥ aceita a segunda conex√£o ap√≥s concluir completamente o atendimento da primeira.

### 1.2 O Comportamento do Backlog

1. Encerre o servidor anterior e inicie o `servergargalo.py`. Este servidor √© configurado com `listen(1)`, que sinaliza ao Sistema Operacional uma fila de espera muito pequena.
2. Execute o `clientenervoso.py` (10 clientes simult√¢neos).
3. Observe os erros `ConnectionRefusedError` e `socket.timeout`.

> üìå **Nota t√©cnica importante:** O par√¢metro passado para `listen()` √© tratado pelo kernel como uma **dica**, n√£o como um limite r√≠gido. Tanto no Linux quanto no Windows, o Sistema Operacional pode aceitar um n√∫mero ligeiramente maior de conex√µes pendentes do que o valor configurado (conforme documentado em `man 2 listen` no Linux e na RFC 793). Por isso, o comportamento exato que voc√™ observar√° **varia de acordo com o sistema operacional**: em alguns casos voc√™ ver√° `ConnectionRefusedError` imediato; em outros, apenas `Timeout`. **Essa variabilidade faz parte da observa√ß√£o experimental desta etapa.** O que importa registrar √©: sob carga suficiente, a fila esgota e novos clientes s√£o recusados ou expiram.

> üîó **Conex√£o com a teoria:** O comportamento observado aqui corresponde diretamente ao mecanismo de *backlog* da interface de sockets descrita em Tanenbaum & Wetherall (2011, cap. 6) e ao problema cl√°ssico de escalabilidade de servidores documentado por Kegel (2006) no artigo *"The C10K Problem"* ‚Äî uma leitura fortemente recomendada para contextualizar o que estamos resolvendo ao longo deste laborat√≥rio.

---

## üß™ Etapa 2: A Solu√ß√£o com Threads ‚Äî Paralelismo via Sistema Operacional

Nesta etapa delegamos o bloqueio de I/O ao Sistema Operacional atrav√©s de Threads, observando os ganhos e os custos dessa abordagem.

### 2.1 Servidor Multithread

1. Inicie o `server.py`.
2. Execute o `clientenervoso.py` (10 clientes simult√¢neos).
3. Observe que todos os clientes conectam quase instantaneamente e o log exibe o n√∫mero de threads ativas (`threading.active_count()`).

> üîé **Ponto de reflex√£o:** O servidor agora delega cada conex√£o para uma Thread separada. O Sistema Operacional realiza a **Troca de Contexto** (*Context Switch*) na CPU para manter todas essas threads ativas de forma concorrente. Cada Thread consome mem√≥ria de pilha (*stack*) alocada pelo SO ‚Äî tipicamente entre 512 KB e 8 MB por thread dependendo da plataforma. Anote o n√∫mero m√°ximo de threads simult√¢neas que voc√™ observou: voc√™ precisar√° desse dado no relat√≥rio.

> üîó **Conex√£o com a teoria:** O ciclo de vida de threads e o custo do *Context Switch* s√£o discutidos em Silberschatz, Galvin & Gagne (2018, cap. 4). A rela√ß√£o entre threads, I/O bloqueante e escalabilidade √© central para compreender as limita√ß√µes desta abordagem frente ao modelo ass√≠ncrono.

---

## üß™ Etapa 3: Alta Performance com I/O Ass√≠ncrono (Event Loop)

Nesta etapa voc√™ implementar√° um servidor TCP ass√≠ncrono utilizando a biblioteca `asyncio` do Python, que implementa o padr√£o de *Event Loop* ‚Äî modelo amplamente adotado em servidores de produ√ß√£o de alta escala (Node.js, Nginx, Uvicorn).

### 3.1 Contexto te√≥rico antes de codar

No modelo ass√≠ncrono, uma **√∫nica Thread** gerencia todas as conex√µes por meio de um la√ßo de eventos (*Event Loop*). Quando uma opera√ß√£o de I/O √© iniciada (ex: esperar dados de um cliente), o Event Loop **n√£o bloqueia** ‚Äî ele simplesmente registra um *callback* e passa para o pr√≥ximo evento pendente. Isso elimina o custo de cria√ß√£o e troca de contexto entre m√∫ltiplas Threads.

A figura abaixo representa conceitualmente a diferen√ßa:

```
Modelo Multithread:          Modelo Ass√≠ncrono (Event Loop):
  Thread 1 ‚Üí Cliente A          Event Loop (Thread √∫nica)
  Thread 2 ‚Üí Cliente B            ‚îú‚îÄ‚îÄ await Cliente A
  Thread 3 ‚Üí Cliente C            ‚îú‚îÄ‚îÄ await Cliente B
  ...                             ‚îî‚îÄ‚îÄ await Cliente C
  (N threads no SO)               (1 thread, N corrotinas)
```

### 3.2 Implementa√ß√£o

Crie um arquivo chamado `server_async.py` na raiz do reposit√≥rio. Voc√™ dever√° implementar um servidor TCP ass√≠ncrono seguindo a estrutura abaixo. Os coment√°rios indicam **o que voc√™ deve preencher** ‚Äî a l√≥gica de cada passo √© sua responsabilidade:

```python
import asyncio

HOST = '127.0.0.1'
PORT = 65432

async def handle_client(reader: asyncio.StreamReader, writer: asyncio.StreamWriter):
    """
    Corrotina chamada pelo Event Loop para cada nova conex√£o.
    Substitui a fun√ß√£o que antes rodava em uma Thread separada.
    """
    addr = writer.get_extra_info('peername')
    print(f"[NOVA CONEX√ÉO] {addr}")

    # 1. Leia os dados enviados pelo cliente (use 'await reader.read(1024)')
    # TODO: ...

    # 2. Simule um processamento pesado SEM bloquear a thread principal.
    #    Use 'await asyncio.sleep(5)' ‚Äî N√ÉO use 'time.sleep(5)'.
    #    Entenda a diferen√ßa: time.sleep bloqueia a Thread; asyncio.sleep
    #    apenas suspende a corrotina e devolve o controle ao Event Loop.
    # TODO: ...

    # 3. Envie a resposta ao cliente (use 'writer.write(...)' e 'await writer.drain()')
    # TODO: ...

    # 4. Feche a conex√£o (use 'writer.close()' e 'await writer.wait_closed()')
    # TODO: ...

    print(f"[DESCONECTADO] {addr}")


async def main():
    """
    Ponto de entrada ass√≠ncrono: cria e inicia o servidor.
    """
    # Use asyncio.start_server() passando handle_client, HOST e PORT
    # TODO: ...

    print(f"[ASS√çNCRONO] Servidor rodando em {HOST}:{PORT} ‚Äî Event Loop ativo.")

    # Mantenha o servidor rodando indefinidamente
    # TODO: ...


if __name__ == "__main__":
    asyncio.run(main())
```

> üìö **Refer√™ncias para esta etapa:**
> - Documenta√ß√£o oficial do `asyncio`: https://docs.python.org/3/library/asyncio.html
> - Kegel, D. (2006). *The C10K Problem*. Dispon√≠vel em: http://www.kegel.com/c10k.html
> - Para uma an√°lise comparativa formal entre modelos de concorr√™ncia, consulte: Ousterhout, J. (1996). *Why Threads Are A Bad Idea (for most purposes)*. USENIX Technical Conference.

### 3.3 Valida√ß√£o

1. Execute seu `server_async.py`.
2. Ataque-o com o `clientenervoso.py`.
3. Verifique que **todos os 10 clientes** s√£o atendidos com sucesso, em concorr√™ncia, com **uma √∫nica Thread** ativa no processo Python.

---

## üì¶ Entrega e Avalia√ß√£o

A entrega ser√° avaliada pelos *commits* neste reposit√≥rio via GitHub Classroom.

**Links √öteis:**
- [P√°gina da nossa Classe no GitHub](https://classroom.github.com/classrooms/76447459-icei-puc-minas-pples-ti-202601-labdamd-g2)
- [Link do Assignment atual](https://classroom.github.com/a/FIuNNNdh)

### O que deve ser commitado?

**1. C√≥digo Fonte ‚Äî `server_async.py`**

O arquivo implementado na Etapa 3, funcionando corretamente e atendendo os 10 clientes do `clientenervoso.py` sem erros.

**2. Relat√≥rio T√©cnico ‚Äî `RELATORIO.md`**

Crie o arquivo `RELATORIO.md` na raiz do reposit√≥rio respondendo de forma t√©cnica e objetiva √†s seguintes quest√µes:

- **Quest√£o 1 ‚Äî Backlog e Recusa de Conex√µes:**
O `clientenervoso.py` apresentou falhas (`ConnectionRefusedError` ou `Timeout`) ao testar o `servergargalo.py`, mas obteve sucesso imediato contra o `server.py`. Explique o motivo t√©cnico, referenciando o conceito de *backlog* TCP e o comportamento do Sistema Operacional. Considere a variabilidade de comportamento entre sistemas operacionais mencionada no roteiro.

- **Quest√£o 2 ‚Äî Custo de Recursos: Threads vs. Event Loop:**
Com base no n√∫mero m√°ximo de threads simult√¢neas que voc√™ observou no `server.py` (via `threading.active_count()`), explique a diferen√ßa no consumo de mem√≥ria e no uso de CPU entre a abordagem Multithread e a abordagem Ass√≠ncrona. Sua resposta deve ser fundamentada na observa√ß√£o experimental, n√£o apenas conceitual.

**3. Desafio Extra** 

Altere o `clientenervoso.py` para disparar **200 conex√µes simult√¢neas** contra seu `server_async.py`.

> ‚ö†Ô∏è Execute este desafio apenas em `localhost`. Nunca aponte para servidores externos ou redes institucionais.

Tire um *screenshot* da execu√ß√£o comprovando que o servidor suportou a carga e anexe a imagem no `RELATORIO.md`.

---

## ‚úÖ Checklist de Entrega

Antes de fazer o *push* final, verifique:

- [ ] `server_async.py` est√° na raiz do reposit√≥rio e executa sem erros
- [ ] `server_async.py` atende os 10 clientes do `clientenervoso.py` com sucesso
- [ ] `RELATORIO.md` responde as duas quest√µes com embasamento t√©cnico
- [ ] O usu√°rio do Professor tem acesso de visualiza√ß√£o ao reposit√≥rio
- [ ] O *push* foi realizado antes do prazo de encerramento da Sprint (01/03/2026)

---

## üìö Refer√™ncias Bibliogr√°ficas

KEGEL, D. **The C10K Problem**, 2006. Dispon√≠vel em: http://www.kegel.com/c10k.html. Acesso em: fev. 2026.

OUSTERHOUT, J. **Why Threads Are A Bad Idea (for most purposes)**. USENIX Technical Conference, 1996.

PYTHON SOFTWARE FOUNDATION. **asyncio ‚Äî Asynchronous I/O**. Python 3 Documentation. Dispon√≠vel em: https://docs.python.org/3/library/asyncio.html. Acesso em: fev. 2026.

SILBERSCHATZ, A.; GALVIN, P. B.; GAGNE, G. **Operating System Concepts**. 10. ed. Hoboken: Wiley, 2018. cap. 4.

TANENBAUM, A. S.; WETHERALL, D. J. **Computer Networks**. 5. ed. Upper Saddle River: Pearson Prentice Hall, 2011. cap. 6.


